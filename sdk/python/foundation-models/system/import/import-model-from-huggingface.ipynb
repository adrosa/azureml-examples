{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import models from Hugging Face hub\n",
    "This sample shows how to import and register models from [HuggingFace hub](https://huggingface.co/models). \n",
    "\n",
    "### How does import work?\n",
    "The import process runs as a job in your AzureML workspace using components from the `azureml` system registry. The models are downloaded and converted to mlflow packaged format. You can then register the models to your AzureML Workspace or Registry that makes them available for inference or fine tuning. \n",
    "\n",
    "### What models are supported for import?\n",
    "Any model from Hugging Face hub can be downloaded using the `download_model` component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, ClientSecretCredential\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "import time\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "workspace_ml_client = MLClient(\n",
    "        credential,\n",
    "        #subscription_id =  \"<SUBSCRIPTION_ID>\",\n",
    "        #resource_group_name =  \"<RESOURCE_GROUP>\",\n",
    "        #workspace_name =  \"WORKSPACE_NAME>\"\n",
    "        subscription_id =  \"21d8f407-c4c4-452e-87a4-e609bfb86248\", #\"<SUBSCRIPTION_ID>\"\n",
    "        resource_group_name =  \"rg-contoso-819prod\", #\"<RESOURCE_GROUP>\",\n",
    "        workspace_name =  \"mlw-contoso-819prod\", #\"WORKSPACE_NAME>\",\n",
    ")\n",
    "\n",
    "# the models, fine tuning pipelines and environments are available in the AzureML system registry, \"azureml-preview\"\n",
    "registry_ml_client = MLClient(credential, registry_name=\"azureml-preview-test1\")\n",
    "\n",
    "experiment_name = \"import-model\"\n",
    "\n",
    "# If you already have a gpu cluster, mention it here. Else will create a new one with the name 'gpu-cluster-big'\n",
    "compute_cluster = \"gpu-cluster-big\"\n",
    "try:\n",
    "    workspace_ml_client.compute.get(compute_cluster)\n",
    "except Exception as ex:\n",
    "    compute = AmlCompute(\n",
    "        name = compute_cluster, \n",
    "        size= \"Standard_ND40rs_v2\",\n",
    "        max_instances= 2 # For multi node training set this to an integer value more than 1\n",
    "    )\n",
    "    workspace_ml_client.compute.begin_create_or_update(compute).wait()\n",
    "\n",
    "# This is the number of GPUs in a single node of the selected 'vm_size' compute. \n",
    "# Setting this to less than the number of GPUs will result in underutilized GPUs, taking longer to train.\n",
    "# Setting this to more than the number of GPUs will result in an error.\n",
    "gpus_per_node = 2 \n",
    "\n",
    "# genrating a unique timestamp that can be used for names and versions that need to be unique\n",
    "timestamp = str(int(time.time())) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.entities import CommandComponent, PipelineComponent, Job, Component\n",
    "from azure.ai.ml import PyTorchDistribution, Input\n",
    "\n",
    "# fetch the download_model component from the system registry\n",
    "download_model_func = registry_ml_client.components.get(name=\"download_model\", version=\"0.0.2\")\n",
    "# fetch the mlflow converter component from the system registry\n",
    "convert_model_to_mlflow_func = registry_ml_client.components.get(name=\"convert_model_to_mlflow\", version=\"0.0.1\")\n",
    "\n",
    "# define the pipeline job\n",
    "@pipeline()\n",
    "def create_pipeline():\n",
    "\n",
    "    download_model_job = download_model_func(\n",
    "        model_id = \"unitary/toxic-bert\",\n",
    "        model_source = \"Huggingface\"\n",
    "    )\n",
    "    convert_model_to_mlflow_job = convert_model_to_mlflow_func(\n",
    "        model_download_details = download_model_job.outputs.model_info,\n",
    "        model_path = download_model_job.outputs.model_output,\n",
    "        #mlflow_flavor = \"hftransformers\",\n",
    "        task_type = \"text-classification\"\n",
    "    )\n",
    "    return {\n",
    "        \"imported_model\": convert_model_to_mlflow_job.outputs.mlflow_model_folder\n",
    "    }\n",
    "\n",
    "pipeline_object = create_pipeline()\n",
    "\n",
    "# don't use cached results from previous jobs\n",
    "pipeline_object.settings.force_rerun = True\n",
    "pipeline_object.settings.default_compute  = compute_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the pipeline job\n",
    "pipeline_job = workspace_ml_client.jobs.create_or_update(pipeline_object, experiment_name=experiment_name)\n",
    "# wait for the pipeline job to complete\n",
    "workspace_ml_client.jobs.stream(pipeline_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "# check if the `trained_model` output is available\n",
    "print (\"pipeline job outputs: \", workspace_ml_client.jobs.get(pipeline_job.name).outputs)\n",
    "\n",
    "#fetch the model from pipeline job output - not working, hence fetching from fine tune child job\n",
    "model_path_from_job = (\"azureml://jobs/{0}/outputs/{1}\".format(pipeline_job.name, \"imported_model\"))\n",
    "\n",
    "imported_model_name = \"unitary-toxic-bert\"\n",
    "\n",
    "print(\"path to register model: \", model_path_from_job)\n",
    "prepare_to_register_model = Model(\n",
    "    path=model_path_from_job,\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    "    name=imported_model_name,\n",
    "    version=timestamp, # use timestamp as version to avoid version conflict\n",
    "    description=imported_model_name + \" imported from Huggingface\"\n",
    ")\n",
    "print(\"prepare to register model: \\n\", prepare_to_register_model)\n",
    "#register the model from pipeline job output \n",
    "registered_model = workspace_ml_client.models.create_or_update(prepare_to_register_model)\n",
    "print (\"registered model: \\n\", registered_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment\n",
    "\n",
    "# Create online endpoint - endpoint names need to be unique in a region, hence using timestamp to create unique endpoint name\n",
    "\n",
    "online_endpoint_name = \"emotion-\" + timestamp\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"Online endpoint for \" + registered_model.name + \", fine tuned model for emotion detection\",\n",
    "    auth_mode=\"key\"\n",
    ")\n",
    "workspace_ml_client.begin_create_or_update(endpoint).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a deployment\n",
    "demo_deployment = ManagedOnlineDeployment(\n",
    "    name=\"demo\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=registered_model.id,\n",
    "    instance_type=\"Standard_DS4_v2\",\n",
    "    instance_count=1,\n",
    ")\n",
    "workspace_ml_client.online_deployments.begin_create_or_update(demo_deployment).wait()\n",
    "endpoint.traffic = {\"demo\": 100}\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.traffic = {\"demo\": 100}\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
